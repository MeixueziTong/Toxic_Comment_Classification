# Toxic_Comment_Classification

Online Communications can be difficult due to the threat of abuse and
harassment. In order to maintain a healthy online conversation
environment, it is important for online communication platforms to build
tools to automatically detect negative behaviors, for example, toxic
comments (i.e. comments that are disrespectful or rude.)

This project was aimed to implement PySpark pipeline tools to perform
Natural Language Processing on raw text and fine-tune a Machine
Learning model to classify toxic comments. The data used for this study
was obtained and adapted from a public dataset from the Kaggle
competition platform, provided by the Conversation AI research team.
